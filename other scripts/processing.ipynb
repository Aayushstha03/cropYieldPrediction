{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crop_df = pd.read_csv(\"data/structured_crop_yield.csv\")\n",
    "weather_df = pd.read_csv(\"data/structured_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Achham' 'Arghakhanchi' 'Baglung' 'Baitadi' 'Bajhang' 'Bajura' 'Banke'\n",
      " 'Bara' 'Bardiya' 'Bhaktapur' 'Bhojpur' 'Chitwan' 'Dadeldhura' 'Dailekh'\n",
      " 'Dang' 'Darchula' 'Dhading' 'Dhankuta' 'Dhanusa' 'Dolakha' 'Dolpa' 'Doti'\n",
      " 'Gorkha' 'Gulmi' 'Humla' 'Ilam' 'Jajarkot' 'Jhapa' 'Jumla' 'Kailali'\n",
      " 'Kalikot' 'Kanchanpur' 'Kapilbastu' 'Kaski' 'Kathmandu' 'Kavre' 'Khotang'\n",
      " 'Lalitpur' 'Lamjung' 'Mahottari' 'Makwanpur' 'Manang' 'Morang' 'Mugu'\n",
      " 'Mustang' 'Myagdi' 'Nawalparasi' 'Nuwakot' 'Okhaldhunga' 'Palpa'\n",
      " 'Panchthar' 'Parbat' 'Parsa' 'Pyuthan' 'Ramechhap' 'Rasuwa' 'Rautahat'\n",
      " 'Rolpa' 'Rukum' 'Rupandehi' 'Salyan' 'Sankhuwasabha' 'Saptari' 'Sarlahi'\n",
      " 'Sindhuli' 'Sindhupalchok' 'Siraha' 'Solukhumbu' 'Sunsari' 'Surkhet'\n",
      " 'Syangja' 'Tanahu' 'Taplejung' 'Tehrathum' 'Udayapur']\n"
     ]
    }
   ],
   "source": [
    "# finding out unique values to iddentify the missing districts inbetween the datasets\n",
    "cropUniqueDistricts = crop_df['DISTRICT_NAME'].unique()\n",
    "print(cropUniqueDistricts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arghakhanchi' 'Baglung' 'Baitadi' 'Bajhang' 'Banke' 'Bara' 'Bardiya'\n",
      " 'Bhaktapur' 'Chitwan' 'Dadeldhura' 'Dailekh' 'Dang' 'Darchula' 'Dhading'\n",
      " 'Dhankuta' 'Dhanusa' 'Dolakha' 'Dolpa' 'Doti' 'Gorkha' 'Gulmi' 'Humla'\n",
      " 'Ilam' 'Jhapa' 'Jumla' 'Kavre' 'Kailali' 'Kanchanpur' 'Kaski' 'Kathmandu'\n",
      " 'Lalitpur' 'Lamjung' 'Mahottari' 'Makwanpur' 'Manang' 'Morang' 'Mugu'\n",
      " 'Mustang' 'Myagdi' 'Nawalparasi' 'Nuwakot' 'Okhaldhunga' 'Palpa'\n",
      " 'Panchthar' 'Parbat' 'Rasuwa' 'Rautahat' 'Rukum' 'Rupandehi' 'Salyan'\n",
      " 'Sankhuwasabha' 'Saptari' 'Sarlahi' 'Sindhuli' 'Solukhumbu' 'Sunsari'\n",
      " 'Surkhet' 'Syangja' 'Tanahu' 'Taplejung' 'Tehrathum' 'Udayapur']\n"
     ]
    }
   ],
   "source": [
    "weatherUniqueDistricts = weather_df['DISTRICT'].unique()\n",
    "print(weatherUniqueDistricts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Kalikot', 'Ramechhap', 'Parsa', 'Achham', 'Siraha', 'Bajura', 'Kapilbastu', 'Jajarkot', 'Sindhupalchok', 'Khotang', 'Rolpa', 'Pyuthan', 'Bhojpur'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "set1 = set(cropUniqueDistricts)\n",
    "set2 = set(weatherUniqueDistricts)\n",
    "# districts that are missing in the weather dataset but present in the crop dataset\n",
    "print(set1-set2)\n",
    "# districts that are missing in the crop dataset but present in the weather dataset\n",
    "# renamed dsitricts with the same convention to prevent disparity\n",
    "print(set2-set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing districts' data has been added and saved to 'complete_weather_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# List of missing districts and their neighboring districts\n",
    "missing_districts = {\n",
    "    'Bhojpur': ['Dhankuta', 'Khotang', 'Sankhuwasabha', 'Solukhumbu'],\n",
    "    'Jajarkot': ['Dailekh', 'Rukum (West)', 'Dolpa', 'Kalikot'],\n",
    "    'Kalikot': ['Jumla', 'Mugu', 'Dailekh', 'Jajarkot'],\n",
    "    'Ramechhap': ['Dolakha', 'Sindhuli', 'Okhaldhunga', 'Kavrepalanchok'],\n",
    "    'Achham': ['Bajura', 'Doti', 'Dailekh', 'Kalikot'],\n",
    "    'Rolpa': ['RukumWest', 'RukumEast', 'Pyuthan', 'Dang'],\n",
    "    'Sindhupalchok': ['Rasuwa', 'Kavrepalanchok', 'Dolakha', 'Nuwakot'],\n",
    "    'Pyuthan': ['Rolpa', 'Gulmi', 'Arghakhanchi', 'Dang'],\n",
    "    'Parsa': ['Bara', 'Rautahat', 'Chitwan', 'Makwanpur'],\n",
    "    'Kapilbastu': ['Rupandehi', 'Arghakhanchi', 'Dang'],\n",
    "    'Siraha': ['Saptari', 'Udayapur', 'Dhanusha'],\n",
    "    'Bajura': ['Bajhang', 'Achham', 'Kalikot', 'Humla'],\n",
    "    'Khotang': ['Udayapur', 'Okhaldhunga', 'Bhojpur', 'Solukhumbu']\n",
    "}\n",
    "\n",
    "# Iterate over each missing district\n",
    "new_rows = []\n",
    "for district, nearby_districts in missing_districts.items():\n",
    "    # Get the list of years from the dataset\n",
    "    years = weather_df['YEAR'].unique()\n",
    "    \n",
    "    for year in years:\n",
    "        # Filter the data for the nearby districts and the given year\n",
    "        nearby_data = weather_df[(weather_df['DISTRICT'].isin(nearby_districts)) & (weather_df['YEAR'] == year)]\n",
    "        \n",
    "        if not nearby_data.empty:\n",
    "            # Compute the average for numeric columns and truncate to 2 decimal places\n",
    "            numeric_columns = nearby_data.select_dtypes(include=['number']).columns\n",
    "            averaged_values = nearby_data[numeric_columns].mean().round(2).to_dict()\n",
    "            \n",
    "            # Create a new row for the missing district\n",
    "            new_row = {'DISTRICT': district, 'YEAR': year}\n",
    "            new_row.update(averaged_values)\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "# Convert new rows to a DataFrame\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Combine the new rows with the original dataset\n",
    "complete_df = pd.concat([weather_df, new_rows_df], ignore_index=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "complete_df.to_csv('complete_weather_data.csv', index=False)\n",
    "\n",
    "print(\"Missing districts' data has been added and saved to 'complete_weather_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "newWeatherDf = pd.read_csv(\"complete_weather_data.csv\")\n",
    "newWeatherUnique = newWeatherDf['DISTRICT'].unique()\n",
    "set3 = set(newWeatherUnique)\n",
    "print(set1-set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# count number of entries per district for the crop yield data set\n",
    "count = crop_df['DISTRICT_NAME'].value_counts()\n",
    "# print the districts that have entries lesss than 210\n",
    "print(count[count < 210])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
